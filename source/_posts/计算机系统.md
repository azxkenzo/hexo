---
title: 计算机系统
date: 2022-11-13 17:52:09
tags:
---

为了在系统上运行 C 程序，每条 C 语句都必须被其他程序转化为一系列的低级**机器语言**指令。然后这些指令按照一种称为**可执行目标程序**的格式打包好，并以
二进制磁盘文件的形式存放起来。目标程序也称为**可执行目标文件**。

在 Unix 系统上，从源文件到目标文件的转化是由**编译器驱动程序**完成的。编译器驱动程序读取源程序文件，并把它翻译成一个可执行目标文件。这个翻译
过程可分为四个阶段。执行这四个阶段的程序（**预处理器**、**编译器**、**汇编器**和**链接器**）一起构成了**编译系统**。
* **预处理阶段**。预处理器根据以字符 # 开头的命令，修改原始的 C 程序。比如 `#include <studio.h>` 命令告诉预处理器读取系统头文件 studio.h 的内容，
并把它直接插入到程序文本中。结果就得到了另一个 C 程序，通常是以 .i 作为文件扩展名。
* **编译阶段**。编译器将文本文件 hello.i 翻译成文本文件 hello.s，它包含一个汇编语言程序。该程序包含函数 main 的定义，定义中的每条语句
都以一种文本格式描述了一条低级机器语言指令。汇编语言为不同高级语言的不同编译器提供了通用的输出语言。
* **汇编阶段**。汇编器将 hello.s 翻译成机器语言指令，并把这些指令打包成一种叫做**可重定位目标程序**的格式，并将结果保存在目标文件 hello.o 中。
hello.o 文件是一个二进制文件，它包含的字节是函数main的指令编码。
* **链接阶段**。hello 程序调用了 printf 函数。printf 函数存在于一个名为 printf.o 的单独的预编译好了的目标文件中，而这个文件必须以某种方式合并到
hello.o 程序中。链接器就负责处理这种合并。结果就得到 hello 文件，它是一个**可执行目标文件**（简称为**可执行文件**），可以被加载到内存中，由系统执行。


有一些重要的原因促使我们必须知道编译系统是如何工作的：
* 优化程序性能。现代编译器都是成熟的工具，通常可以生成很好的代码。但是，为了在 C 程序中做出好的编码选择，需要了解一些机器代码以及编译器将不同 C 语句转化为机器代码的方式。
比如，一个 switch 语句是否总是比一系列的 if-else 语句高效得多？一个函数调用的开销有多大？while 循环比 for 循环更有效吗？指针引用比数组索引更有效吗？
为什么将循环求和的结果放到一个本地变量中，会比将其放到一个通过引用传递过来的参数中，运行起来快很多？
* 理解链接时出现的错误。一些最令人困扰的程序错误往往都与链接器操作有关。比如，链接器报告说它无法解析一个引用，这是什么意思？静态变量和全局变量的区别是什么？
* 避免安全漏洞。缓冲区溢出错误是造成大多数网络和Internet服务器上安全漏洞的主要原因。存在这些错误是因为很少有人能够理解需要限制从不受信任的源接收数据的数量和格式。
学习安全编程的第一步就是理解数据和控制信息存储在程序栈上的方式会引起的后果。


Unix 中的 shell 是一个命令行解释器，它输出一个字符，等待输入一个命令行，然后执行这个命令。如果该命令行的第一个单词不是一个内置的 shell 命令，那么 shell 就会假设这是一个可执行文件的名字，
它将加载并运行这个文件。


了解一个典型的系统的硬件组织：
1. **总线**  
贯穿整个系统的是一组电子管道，称为总线。，它携带信息字节并负责在各个部件间传递。通常总线被设计为传送定长的字节块，也就是字（word）。字中字节数（即字长）是一个基本的系统参数。现在大多数机器字长要么是4个字节，要么是8个字节。
2. **I/O 设备**  
I/O（输入/输出）设备是系统与外部世界的联系通道。每个 I/O 设备都通过一个控制器或适配器与 I/O 总线相连。控制器和适配器之间的区别主要在于它们的封装方式。
控制器是 I/O 设备本身或者系统的主印制电路板（主板）上的芯片组。而适配器则是一块插在主板插槽上的卡。它们的功能都是在 I/O 总线和 I/O 设备之间传递信息。
3. **主存**  
主存是一个临时存储设备。在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组动态随机存取存储器（DRAM）芯片组成的。从逻辑上来说，
存储器是一个线性的字节数组，每个字节都有其唯一的地址（数组索引），这些地址是从零开始的。一般来说，组成程序的每条机器指令都由不同数量的字节构成。
4. 处理器  
处理器是解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC）。在任何时刻，PC 都指向主存中的某条机器语言指令（即含有该条指令的地址）。
处理器看上去是按照一个非常简单的指令执行模型来操作的，这个模型是由指令集架构决定的。在这个模型中，指令按照严格的顺序执行，而执行一条指令包含执行一系列的步骤。
处理器从程序计数器指向的内存处读取指令，解释指令中的位，执行该指令指示的简单操作，然后更新PC，使其指向下一条指令。  
这样的简单操作并不多，它们围绕着主存、寄存器文件和算术/逻辑单元（ALU）进行。寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字。
ALU 计算新的数据和地址值。CPU 在指令的要求下可能会执行这些操作：
   * 加载：从主存复制一个字节或者一个字到寄存器，以覆盖寄存器原来的内容
   * 存储：从寄存器复制一个字节或者一个字到主存的某个位置，以覆盖这个位置原来的内容
   * 操作：把两个寄存器的内容复制到 ALU，ALU 对这两个字做算术运算，并将结果存放到一个寄存器中，以覆盖该寄存器中原来的内容
   * 跳转：从指令本身中抽取一个字，并将这个字复制到 PC 中，以覆盖 PC 中原来的值

**指令集架构**描述的是每条机器代码指令的效果；而**微体系结构**描述的是处理器实际上是如何实现的。

运行hello程序时发生了什么：
1. 在键盘上输入"./hello"后，shell 程序将字符逐一读入寄存器，再把它存放到内存中。
2. 敲回车键后，shell 执行一系列指令来加载可执行的 hello 文件，这些指令将 hello 目标文件中的代码和数据从磁盘复制到主存。利用直接存储器存取（DMA）技术，数据可以不通过处理器而直接从磁盘到达主存。
3. 一旦目标文件 hello 中的代码和数据被加载到主存，处理器就开始执行 hello 程序的main程序中的机器语言指令。这些指令将"hello，world"字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备。

这个简单的示例揭示了一个重要的问题，即系统花费了大量的时间把信息从一个地方挪到另一个地方。这些复制就是开销，减慢了程序真正的工作。因此，系统设计者的一个主要目标就是使这些复制操作尽可能快地完成。

操作系统有两个基本功能：
1. 防止硬件被失控的应用程序滥用
2. 向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。

操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个功能。文件是对 I/O 设备的抽象表示，虚拟内存是对主存和磁盘 I/O 设备的抽象表示，进程则是对处理器、主存和 I/O 设备的抽象表示。

20世纪80年代中期，Unix 厂商试图通过加入新的、往往不兼容的特性来使他们的程序与众不同，麻烦也就随之而来。为了阻止这种趋势，IEEE 开始努力标准化 Unix 开发，后来由 Richard 命名为"Posix"。
结果就得到来一系列的标准，称作 Posix 标准。这套标准涵盖了很多方面，比如 Unix 系统调用的 C 语言接口、shell 程序和工具、线程及网络编程。最近，一个被称为"标准Unix规范"的独立标准化工作已经与 Posix 一起创建了统一的 Unix 系统标准。


### 进程
程序在现代系统上运行时，操作系统会提供一个假象，就好像系统上只有这个程序在运行。程序看上去是独占地使用处理器、主存和 I/O 设备。处理器看上去就像在不间断地一条接一条地执行程序中的指令，
即该程序的代码和数据是系统内存中唯一的对象。这些假象是通过进程的概念来实现的。

进程是操作系统对一个正在运行的程序的一种抽象。并发运行，是说一个进程的指令和另一个进程的指令是交错运行的。一个 CPU 看上去都像是在并发地执行多个进程，
这是通过处理器在进程间切换来实现的。操作系统实现这种交错执行的机制称为上下文切换。

操作系统保持跟踪进程运行所需要的所有状态信息。这种状态，也就是上下文，包括比如 PC 和寄存器文件的当前值，以及主存的内容。当操作系统决定把控制权从当前进程转移到某个新进程时，就会进行上下文切换，
即保存当前进程的上下文，恢复新进程的上下文，然后将控制权传递到新进程。

从一个进程到另一个进程的转换是由操作系统内核管理的，内核是操作系统代码常驻主存的部分。当应用程序需要操作系统的某些操作时，比如读写文件，它就执行一条特殊的系统调用指令，
将控制权传递给内核。然后内核执行被请求的操作并返回给应用程序。内核不是一个独立的进程，它是系统管理全部进程所用代码和数据结构的集合。

### 虚拟内存
虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存都是一致的，称为虚拟地址空间。在 Linux 中，
地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有进程来说都是一样的。地址空间的底部区域存放用户进程定义的代码和数据。

每个进程看到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能。从最低的地址开始，逐步向上介绍：
* 程序代码和数据。对所有的进程来说，代码是从同一固定地址开始，紧接着的是和 C 全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的。
* 堆。代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被指定了大小，与此不同，当调用像 malloc 和 free 这样的 C 标准库函数时，堆可以在运行时动态地扩展和收缩。
* 共享库。用来存放像 C 标准库和数学库这样的共享库的代码和数据的区域。
* 栈。位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地扩展和收缩。
* 内核虚拟内存。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。相反，它们必须调用内核来执行这些操作。

### 文件
文件就是字节序列，仅此而已。每个 I/O 设备，包括磁盘、键盘、显示器、甚至网络，都可以看成是文件。系统中所有输入输出都是通过使用一小组称为 Unix I/O 的系统函数调用读写文件来实现的。


### Amdahl 定律
该定律的主要思想是，当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。Amdahl 定律主要观点--要想显著加速整个系统，必须提升全系统中相当大的部分的速度


### 并发和并行
并发（concurrency）是一个通用的概念，指一个同时具有多个活动的系统；而并行（parallelism）指的是用并发来使一个系统运行得更快。

#### 线程级并发
传统意义上，这种并发执行知识模拟出来的，是通过使一台计算机在它正在执行的进程间快速切换来实现的。

超线程，有时称为同时多线程，是一项允许一个 CPU 执行多个控制流的技术。它涉及 CPU 某些硬件有多个备份，比如程序计数器和寄存器文件。常规的处理器需要大约20000个时钟周期做不同线程间的转换，
而超线程的处理器可以在单个周期的基础上决定要执行哪一个线程。

#### 指令级并行
现代处理器可以同时执行多条指令的属性称为指令级并行。早期的微处理器，需要多个（通常是3-10个）时钟周期来执行一条指令。最近的处理器可以保持每个时钟周期2-4条指令的执行速率。其实每条指令从开始到结束需要长得多的事件，大约20个或者更多周期，
但是处理器使用了技巧来同时处理多达100条指令。

#### 单指令、多数据并行
许多处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即 SIMD 并行。


### 抽象
在处理器里，指令级架构提供了对实际处理器硬件的抽象。

虚拟机，它提供对整个计算机的抽象，包括操作系统、处理器和程序。
















